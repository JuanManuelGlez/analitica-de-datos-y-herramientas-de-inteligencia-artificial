{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas de evaluación\n",
    "## Juan Manuel González Ascencio - A00572003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confussion_matrix(objective_class, real_classes, predicted_classes):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    real_classes = list(real_classes)\n",
    "    predicted_classes = list(predicted_classes)\n",
    "\n",
    "    for i in range(len(real_classes)):\n",
    "        if real_classes[i] == objective_class:\n",
    "            if predicted_classes[i] == objective_class:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if predicted_classes[i] == objective_class:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    # Print matrix\n",
    "    df_matrix = pd.DataFrame({\n",
    "        'Positive': [TP, FP],\n",
    "        'Negative': [FN, TN]\n",
    "    }, index=['Positive', 'Negative'])\n",
    "    print(df_matrix)\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def evaluation_metrics(TP, TN, FP, FN):\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return accuracy, precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Positive  Negative\n",
      "Positive         3         3\n",
      "Negative         5         4\n",
      "Accuracy: 0.4666666666666667\n",
      "Precision: 0.375\n",
      "Recall: 0.5\n",
      "F1 Score: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "clase_objetivo = 'Neg'\n",
    "real = pd.Series(['Pos','Pos','Neg','Neg','Neg','Pos','Pos','Pos','Pos','Pos','Neg','Pos','Neg','Pos','Neg'])\n",
    "hipotesis = ['Pos','Neg','Neg','Neg','Pos','Pos','Pos','Neg','Neg','Pos','Pos','Neg','Neg','Neg','Pos']\n",
    "\n",
    "TP, TN, FP, FN = confussion_matrix(clase_objetivo, real, hipotesis)\n",
    "accuracy, precision, recall, f1_score = evaluation_metrics(TP, TN, FP, FN)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>245</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.851</td>\n",
       "      <td>28</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.466</td>\n",
       "      <td>27</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.181</td>\n",
       "      <td>29</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.580</td>\n",
       "      <td>24</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     3   158    76    36   245  31.6  0.851   28  tested_positive\n",
       "1     1   117    60    23   106  33.8  0.466   27  tested_negative\n",
       "2     1   107    50    19     0  28.3  0.181   29  tested_negative\n",
       "3     1    90    62    12    43  27.2  0.580   24  tested_negative\n",
       "4     2    88    58    26    16  28.4  0.766   22  tested_negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes-1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera una función que reciba como parámetros una clase objetivo, la lista de clases reales y de clases asignadas por un modelo, imprima la matriz de confusión y retorne los valores de TP, TN, FP y FN. Esta función recibe 3 parámetros y retorna 4 valores\n",
    "\n",
    "def confusion_matrix(clase_objetivo, clases_reales, clases_asignadas):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(clases_reales)):\n",
    "        if clases_reales[i] == clase_objetivo and clases_asignadas[i] == clase_objetivo:\n",
    "            TP += 1\n",
    "        elif clases_reales[i] != clase_objetivo and clases_asignadas[i] != clase_objetivo:\n",
    "            TN += 1\n",
    "        elif clases_reales[i] != clase_objetivo and clases_asignadas[i] == clase_objetivo:\n",
    "            FP += 1\n",
    "        elif clases_reales[i] == clase_objetivo and clases_asignadas[i] != clase_objetivo:\n",
    "            FN += 1\n",
    "    print(f'TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}')\n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera una función que reciba los valores de TP, TN, FP y FN y retorne los valores de precision, recall y F1. Esta función recibe 4 parámetros y retorna 3 valores\n",
    "\n",
    "def metrics(TP, TN, FP, FN):\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 3, TN: 4, FP: 5, FN: 3\n",
      "Precision: 0.375, Recall: 0.5, F1: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "Clase_objetivo='Neg'\n",
    "real=pd.Series(['Pos','Pos','Neg','Neg','Neg','Pos','Pos','Pos','Pos','Pos','Neg','Pos','Neg','Pos','Neg'])\n",
    "hipotesis=['Pos','Neg','Neg','Neg','Pos','Pos','Pos','Neg','Neg','Pos','Pos','Neg','Neg','Neg','Pos']\n",
    "\n",
    "TP, TN, FP, FN = confusion_matrix(Clase_objetivo, real, hipotesis)\n",
    "precision, recall, F1 = metrics(TP, TN, FP, FN)\n",
    "print(f'Precision: {precision}, Recall: {recall}, F1: {F1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genera al menos 5 modelos utilizando el conjunto de datos \"diabetes\" y el clasificador de árbol de decisión. Puedes cambiar el nivel de profundidad, instancias por hoja o el porcentaje de instancias para evaluación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con profundidad 1\n",
      "          Positive  Negative\n",
      "Positive        34        16\n",
      "Negative        32        72\n",
      "Accuracy: 0.6883116883116883\n",
      "Precision: 0.5151515151515151\n",
      "Recall: 0.68\n",
      "F1 Score: 0.5862068965517241\n",
      "\n",
      "Modelo con profundidad 2\n",
      "          Positive  Negative\n",
      "Positive        15        35\n",
      "Negative         5        99\n",
      "Accuracy: 0.7402597402597403\n",
      "Precision: 0.75\n",
      "Recall: 0.3\n",
      "F1 Score: 0.4285714285714285\n",
      "\n",
      "Modelo con profundidad 3\n",
      "          Positive  Negative\n",
      "Positive        33        17\n",
      "Negative        28        76\n",
      "Accuracy: 0.7077922077922078\n",
      "Precision: 0.5409836065573771\n",
      "Recall: 0.66\n",
      "F1 Score: 0.5945945945945946\n",
      "\n",
      "Modelo con profundidad 4\n",
      "          Positive  Negative\n",
      "Positive        22        28\n",
      "Negative        20        84\n",
      "Accuracy: 0.6883116883116883\n",
      "Precision: 0.5238095238095238\n",
      "Recall: 0.44\n",
      "F1 Score: 0.4782608695652174\n",
      "\n",
      "Modelo con profundidad 5\n",
      "          Positive  Negative\n",
      "Positive        24        26\n",
      "Negative        20        84\n",
      "Accuracy: 0.7012987012987013\n",
      "Precision: 0.5454545454545454\n",
      "Recall: 0.48\n",
      "F1 Score: 0.5106382978723404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hacemos 5 modelos de arboles de decisión con diferentes profundidades\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "X = df.drop(columns='class')\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print (f'Modelo con profundidad {i}')\n",
    "\n",
    "    #Sacamos las metricas\n",
    "    TP, TN, FP, FN = confussion_matrix('tested_positive', y_test, y_pred)\n",
    "    accuracy, precision, recall, f1_score = evaluation_metrics(TP, TN, FP, FN)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1_score}')\n",
    "    print('')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podmeos ver que la mejor profundidad para este modelo es la dos, ya que tuvo el accuracy mas alto de todas, pero eso costo un poco enm el recall ya que unicamente tuvo .3, cuando el modelo con profundidad 1 o 3 tuvieron .66 y .68 respectivamente, por lo que habría que analisar bien la situación para ver cual es el mejor modelo para el esenario con el que trabajemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2277755207.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter nbconvert --to html /content/4.2.2.ipynb\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#convertimos a html\n",
    "%%shell\n",
    "jupyter nbconvert --to html /content/4.2.2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
